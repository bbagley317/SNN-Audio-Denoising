{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import snntorch as snn\n",
    "from snntorch import spikeplot as splt\n",
    "from snntorch import spikegen\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullbandModel(nn.Module):\n",
    "    def __init__(self, freq_bins, time_bins, hidden_dim, beta=0.9):\n",
    "        \"\"\"\n",
    "        Fullband Model with normalization, spiking neuron layer, and a linear layer.\n",
    "        Args:\n",
    "        - freq_bins: Number of frequency bins in the spectrogram.\n",
    "        - time_bins: Number of time bins in the spectrogram.\n",
    "        - hidden_dim: Number of hidden units for the spiking neuron layer.\n",
    "        - beta: Decay parameter for the LIF neuron.\n",
    "        \"\"\"\n",
    "        super(FullbandModel, self).__init__()\n",
    "        \n",
    "        self.freq_bins = freq_bins\n",
    "        self.time_bins = time_bins\n",
    "        self.input_dim = freq_bins * time_bins  # Flattened input feature size\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        # Layers\n",
    "        self.normalization = nn.LayerNorm(self.input_dim)  # Normalize input features\n",
    "        self.spikingneuron = snn.Leaky(beta=beta)          # Leaky Integrate-and-Fire neuron\n",
    "        self.linear = nn.Linear(self.input_dim, self.hidden_dim)  # Linear transformation\n",
    "\n",
    "    def forward(self, x, num_steps=10):\n",
    "        \"\"\"\n",
    "        Forward pass for the FullbandModel with time-stepped spiking neuron dynamics.\n",
    "        Args:\n",
    "        - x: Input tensor of shape (batch_size, frequency_bins, time_bins).\n",
    "        - num_steps: Number of time steps for spiking neuron simulation.\n",
    "        Returns:\n",
    "        - spk_rec: Spiking activity across timesteps (num_steps, batch_size, hidden_dim).\n",
    "        - mem_rec: Membrane potential across timesteps (num_steps, batch_size, hidden_dim).\n",
    "        \"\"\"\n",
    "        batch_size, freq_bins, time_bins = x.shape\n",
    "        assert freq_bins == self.freq_bins and time_bins == self.time_bins, \\\n",
    "            \"Input dimensions must match model initialization dimensions.\"\n",
    "\n",
    "        # Flatten the spectrogram into 1D vectors\n",
    "        x = x.view(batch_size, -1)  # Shape: (batch_size, input_dim)\n",
    "\n",
    "        # Normalize the input\n",
    "        x = self.normalization(x)\n",
    "\n",
    "        # Initialize membrane potentials for the spiking neuron\n",
    "        mem = torch.zeros((batch_size, self.hidden_dim), dtype=torch.float32, device=x.device)\n",
    "\n",
    "        # Record spiking activity and membrane potentials\n",
    "        spk_rec = []\n",
    "        mem_rec = []\n",
    "\n",
    "        for step in range(num_steps):\n",
    "            # Linear transformation\n",
    "            cur = self.linear(x)\n",
    "\n",
    "            # Spiking neuron dynamics\n",
    "            spk, mem = self.spikingneuron(cur, mem)\n",
    "\n",
    "            # Record outputs\n",
    "            spk_rec.append(spk)\n",
    "            mem_rec.append(mem)\n",
    "\n",
    "        # Stack outputs across timesteps\n",
    "        spk_rec = torch.stack(spk_rec, dim=0)  # Shape: (num_steps, batch_size, hidden_dim)\n",
    "        mem_rec = torch.stack(mem_rec, dim=0)  # Shape: (num_steps, batch_size, hidden_dim)\n",
    "\n",
    "        return spk_rec, mem_rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubbandModel(nn.Module):\n",
    "    def __init__(self, hidden_dim, num_steps, beta=0.9):\n",
    "        \"\"\"\n",
    "        Subband Model with normalization, spiking neuron layer, and a linear layer.\n",
    "        Args:\n",
    "        - hidden_dim: Number of hidden units for the spiking neuron layer.\n",
    "        - num_steps: Number of timesteps for spiking neuron simulation.\n",
    "        - beta: Decay parameter for the LIF neuron.\n",
    "        \"\"\"\n",
    "        super(SubbandModel, self).__init__()\n",
    "\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_steps = num_steps\n",
    "        self.spikingneuron = snn.Leaky(beta=beta)  # Leaky Integrate-and-Fire neuron\n",
    "        self.linear = None  # Linear layer to be initialized dynamically\n",
    "\n",
    "    def forward(self, x, num_steps=None):\n",
    "        \"\"\"\n",
    "        Forward pass for the SubbandModel with time-stepped spiking neuron dynamics.\n",
    "        Args:\n",
    "        - x: Input tensor of shape (batch_size, subband_dim).\n",
    "        - num_steps: Number of time steps for spiking neuron simulation.\n",
    "        Returns:\n",
    "        - spk_rec: Spiking activity across timesteps (num_steps, batch_size, hidden_dim).\n",
    "        - mem_rec: Membrane potential across timesteps (num_steps, batch_size, hidden_dim).\n",
    "        \"\"\"\n",
    "        if num_steps is None:\n",
    "            num_steps = self.num_steps\n",
    "\n",
    "        batch_size, subband_dim = x.shape\n",
    "\n",
    "        # Initialize normalization and linear layers dynamically\n",
    "        if not hasattr(self, 'normalization') or self.normalization is None:\n",
    "            self.normalization = nn.LayerNorm(subband_dim).to(x.device)\n",
    "        if self.linear is None:\n",
    "            self.linear = nn.Linear(subband_dim, self.hidden_dim).to(x.device)\n",
    "\n",
    "        # Normalize input\n",
    "        x = self.normalization(x)\n",
    "\n",
    "        # Initialize membrane potentials for the spiking neuron\n",
    "        mem = torch.zeros((batch_size, self.hidden_dim), dtype=torch.float32, device=x.device)\n",
    "\n",
    "        # Record the outputs\n",
    "        spk_rec = []\n",
    "        mem_rec = []\n",
    "\n",
    "        for step in range(num_steps):\n",
    "            cur = self.linear(x)  # Linear transformation\n",
    "            spk, mem = self.spikingneuron(cur, mem)  # Spiking neuron dynamics\n",
    "            spk_rec.append(spk)\n",
    "            mem_rec.append(mem)\n",
    "\n",
    "        # Stack the recorded values across timesteps\n",
    "        spk_rec = torch.stack(spk_rec, dim=0)  # Shape: (num_steps, batch_size, hidden_dim)\n",
    "        mem_rec = torch.stack(mem_rec, dim=0)  # Shape: (num_steps, batch_size, hidden_dim)\n",
    "\n",
    "        return spk_rec, mem_rec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency_partition(spectrogram, num_subbands):\n",
    "    \"\"\"\n",
    "    Splits the input tensor into subbands along the second dimension.\n",
    "    Args:\n",
    "    - spectrogram: Input tensor of shape (batch_size, hidden_dim).\n",
    "    - num_subbands: Number of subbands to split the hidden_dim into.\n",
    "    Returns:\n",
    "    - subbands: List of tensors, each of shape (batch_size, subband_size).\n",
    "    \"\"\"\n",
    "    batch_size, hidden_dim = spectrogram.shape\n",
    "    subband_size = hidden_dim // num_subbands\n",
    "\n",
    "    # Split along the hidden_dim axis\n",
    "    subbands = torch.split(spectrogram, subband_size, dim=1)\n",
    "    # print(f\"Number of Subbands (fp func): {len(subbands)}\")\n",
    "    return subbands\n",
    "\n",
    "\n",
    "def frequency_reconstruct(subbands):\n",
    "    \"\"\"\n",
    "    Reconstructs the full spectrogram from processed subbands.\n",
    "    Args:\n",
    "    - subbands: List of tensors, each of shape (batch_size, subband_size, time_bins).\n",
    "    Returns:\n",
    "    - reconstructed: Tensor of shape (batch_size, frequency_bins, time_bins).\n",
    "    \"\"\"\n",
    "    # Concatenate the processed subbands along the frequency axis\n",
    "    reconstructed = torch.cat(subbands, dim=1)\n",
    "    return reconstructed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepFilteringLayer(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, num_filters=64):\n",
    "        super(DeepFilteringLayer, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(input_dim, num_filters, kernel_size=3, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv1d(num_filters, num_filters, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv1d(num_filters, output_dim, kernel_size=1)\n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode='linear', align_corners=True)  # Add this layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.upsample(x)  # Upsample to match original dimensions\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IntegratedModel(nn.Module):\n",
    "    def __init__(self, freq_bins, time_bins, hidden_dim, num_steps, num_subbands, beta=0.9):\n",
    "        \"\"\"\n",
    "        Integrated model with FullbandModel, SubbandModels, and per-subband DeepFilteringLayers.\n",
    "        Args:\n",
    "        - freq_bins: Number of frequency bins in the spectrogram.\n",
    "        - time_bins: Number of time bins in the spectrogram.\n",
    "        - hidden_dim: Number of hidden units for the spiking neuron layer.\n",
    "        - num_steps: Number of timesteps for spiking neuron simulation.\n",
    "        - num_subbands: Number of frequency subbands.\n",
    "        - beta: Decay parameter for the LIF neuron.\n",
    "        \"\"\"\n",
    "        super(IntegratedModel, self).__init__()\n",
    "\n",
    "        self.freq_bins = freq_bins\n",
    "        self.time_bins = time_bins\n",
    "        self.num_subbands = num_subbands\n",
    "\n",
    "        subband_size = freq_bins // num_subbands\n",
    "\n",
    "        # Fullband model\n",
    "        self.fullband_model = FullbandModel(freq_bins, time_bins, hidden_dim, beta)\n",
    "\n",
    "        # Subband models\n",
    "        self.subband_models = nn.ModuleList([\n",
    "            SubbandModel(hidden_dim, num_steps, beta)\n",
    "            for _ in range(num_subbands)\n",
    "        ])\n",
    "\n",
    "        # Per-subband Deep Filtering Layers\n",
    "        self.deep_filtering_layers = nn.ModuleList([\n",
    "            DeepFilteringLayer(input_dim=hidden_dim, output_dim=subband_size)\n",
    "            for _ in range(num_subbands)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x, num_steps=10, clean_time_bins=None):\n",
    "        \"\"\"\n",
    "        Forward pass through the IntegratedModel.\n",
    "        Args:\n",
    "        - x: Input tensor of shape (batch_size, frequency_bins, time_bins).\n",
    "        - num_steps: Number of time steps for spiking neuron simulation.\n",
    "        - clean_time_bins: Time bins of the clean tensor for interpolation (optional).\n",
    "        Returns:\n",
    "        - filtered_output: Tensor after deep filtering and interpolation.\n",
    "        \"\"\"\n",
    "        # Fullband processing\n",
    "        fullband_output, _ = self.fullband_model(x, num_steps)\n",
    "\n",
    "        # Subband processing\n",
    "        subbands = frequency_partition(fullband_output[-1], self.num_subbands)\n",
    "        subband_outputs = [\n",
    "            self.subband_models[i](subband, num_steps=num_steps)[0][-1]\n",
    "            for i, subband in enumerate(subbands)\n",
    "        ]\n",
    "\n",
    "        # Per-subband deep filtering\n",
    "        filtered_subbands = [\n",
    "            self.deep_filtering_layers[i](subband_output.unsqueeze(-1)).squeeze(-1)\n",
    "            for i, subband_output in enumerate(subband_outputs)\n",
    "        ]\n",
    "\n",
    "        # Concatenate filtered subbands along the feature dimension\n",
    "        concatenated_output = torch.cat(filtered_subbands, dim=1)  # Shape: (batch_size, freq_bins)\n",
    "\n",
    "        # Add a singleton spatial dimension for interpolation\n",
    "        concatenated_output = concatenated_output.unsqueeze(-1)  # Shape: (batch_size, freq_bins, 1)\n",
    "\n",
    "        # Use clean_time_bins for interpolation if provided\n",
    "        target_time_bins = clean_time_bins if clean_time_bins is not None else self.time_bins\n",
    "\n",
    "        # Interpolate to match the original spectrogram dimensions\n",
    "        interpolated_output = torch.nn.functional.interpolate(\n",
    "            concatenated_output, size=(self.freq_bins, target_time_bins), mode='bilinear', align_corners=True\n",
    "        )\n",
    "\n",
    "        # Remove the singleton spatial dimension\n",
    "        filtered_output = interpolated_output.squeeze(-1)  # Shape: (batch_size, freq_bins, target_time_bins)\n",
    "\n",
    "        return filtered_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def si_sdr_loss(clean, enhanced, eps=1e-8):\n",
    "    \"\"\"\n",
    "    Computes the Scale-Invariant Signal-to-Distortion Ratio (SI-SDR) Loss.\n",
    "    Args:\n",
    "    - clean: Ground truth clean signal (batch_size, time_steps).\n",
    "    - enhanced: Enhanced (predicted) signal (batch_size, time_steps).\n",
    "    - eps: Small value to avoid division by zero.\n",
    "    Returns:\n",
    "    - Loss value (negative SI-SDR).\n",
    "    \"\"\"\n",
    "    # Ensure signals have zero mean\n",
    "    clean = clean - torch.mean(clean, dim=-1, keepdim=True)\n",
    "    enhanced = enhanced - torch.mean(enhanced, dim=-1, keepdim=True)\n",
    "\n",
    "    # Compute scaling factor\n",
    "    scale = torch.sum(clean * enhanced, dim=-1, keepdim=True) / (torch.sum(clean**2, dim=-1, keepdim=True) + eps)\n",
    "\n",
    "    # Projection of enhanced signal onto clean signal\n",
    "    projection = scale * clean\n",
    "\n",
    "    # Compute noise (residual)\n",
    "    noise = enhanced - projection\n",
    "\n",
    "    # SI-SDR calculation with stabilization\n",
    "    numerator = torch.sum(projection**2, dim=-1) + eps\n",
    "    denominator = torch.sum(noise**2, dim=-1) + eps\n",
    "    si_sdr = 10 * torch.log10(numerator / denominator)\n",
    "\n",
    "    # Return negative SI-SDR as the loss\n",
    "    return -torch.mean(si_sdr)\n",
    "\n",
    "def composite_loss(filtered_output, clean_tensor, \n",
    "                   filtered_output_complex=None, clean_tensor_complex=None, \n",
    "                   alpha=0.5, beta=0.3, p=1, target_metric=4.5):\n",
    "    \"\"\"\n",
    "    Composite loss function combining SI-SDR, proxy MetricGAN+ generator loss, and frequency loss.\n",
    "    Args:\n",
    "    - filtered_output: Time-domain enhanced signal.\n",
    "    - clean_tensor: Time-domain clean signal.\n",
    "    - filtered_output_complex: Complex spectrogram of enhanced signal.\n",
    "    - clean_tensor_complex: Complex spectrogram of clean signal.\n",
    "    - alpha: Weight for SI-SDR loss.\n",
    "    - beta: Weight for proxy MetricGAN+ generator loss.\n",
    "    - p: Power for dynamic range compression in frequency-domain loss.\n",
    "    - target_metric: Ideal target metric score (e.g., 4.5 for PESQ-like proxy metric).\n",
    "    Returns:\n",
    "    - Combined loss value.\n",
    "    \"\"\"\n",
    "    # SI-SDR Loss\n",
    "    si_sdr = si_sdr_loss(clean_tensor, filtered_output)\n",
    "\n",
    "    # Proxy MetricGAN+ Generator Loss\n",
    "    if filtered_output_complex is not None and clean_tensor_complex is not None:\n",
    "        def spectrogram_metric_loss(clean_spectrogram, enhanced_spectrogram, p=1):\n",
    "            magnitude_loss = torch.mean(torch.abs(torch.abs(clean_spectrogram)**p - torch.abs(enhanced_spectrogram)**p))\n",
    "            phase_loss = torch.mean(torch.abs(torch.angle(clean_spectrogram) - torch.angle(enhanced_spectrogram)))\n",
    "            return magnitude_loss + phase_loss\n",
    "\n",
    "        gen_loss = spectrogram_metric_loss(clean_tensor_complex, filtered_output_complex, p=p)\n",
    "        proxy_metric_loss = (gen_loss - target_metric) ** 2\n",
    "    else:\n",
    "        proxy_metric_loss = 0\n",
    "\n",
    "    # Frequency-Domain Loss\n",
    "    if filtered_output_complex is not None and clean_tensor_complex is not None:\n",
    "        freq_loss = torch.mean(\n",
    "            torch.abs(filtered_output_complex.abs()**p - clean_tensor_complex.abs()**p)\n",
    "        ) + torch.mean(\n",
    "            torch.abs(filtered_output_complex - clean_tensor_complex)\n",
    "        )\n",
    "    else:\n",
    "        freq_loss = 0\n",
    "\n",
    "    # Composite Loss\n",
    "    total_loss = alpha * si_sdr + beta * proxy_metric_loss + freq_loss\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm  # For tracking progress\n",
    "\n",
    "# Paths to the feature and label directories\n",
    "feature_dir = \"E:/CS541 - Deep Learning/noisy_audio_np\"\n",
    "label_dir = \"E:/CS541 - Deep Learning/clean_audio_np\"\n",
    "\n",
    "# Load all feature and label file paths\n",
    "feature_files = sorted(os.listdir(feature_dir))\n",
    "label_files = sorted(os.listdir(label_dir))\n",
    "\n",
    "assert len(feature_files) == len(label_files), \"Mismatch between feature and label file counts!\"\n",
    "\n",
    "# Model parameters\n",
    "freq_bins, time_bins = 128, 860  # Based on the dimensions of your spectrograms\n",
    "hidden_dim = 64                  # Hidden dimension for spiking neurons\n",
    "num_steps = 10                   # Number of timesteps for spiking neurons\n",
    "num_subbands = 4                 # Number of subbands (adjusted for even division)\n",
    "beta = 0.9                       # Decay parameter for LIF neurons\n",
    "\n",
    "# Initialize the model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = IntegratedModel(freq_bins, time_bins, hidden_dim, num_steps, num_subbands, beta).to(device)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Track losses\n",
    "losses = []\n",
    "\n",
    "epochs = 3\n",
    "\n",
    "for _ in range(epochs):\n",
    "    # Training loop\n",
    "    for idx in tqdm(range(len(feature_files)), desc=\"Processing files\"):\n",
    "        feature_path = os.path.join(feature_dir, feature_files[idx])\n",
    "        label_path = os.path.join(label_dir, label_files[idx])\n",
    "\n",
    "        noisy_tensor = torch.tensor(np.load(feature_path)).unsqueeze(0).to(device)\n",
    "        clean_tensor = torch.tensor(np.load(label_path)).unsqueeze(0).to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        filtered_output = model(noisy_tensor, num_steps=10, clean_time_bins=clean_tensor.shape[2])\n",
    "\n",
    "        # Compute composite loss\n",
    "        total_loss = composite_loss(\n",
    "            filtered_output, clean_tensor,\n",
    "            filtered_output_complex=None, clean_tensor_complex=None,  # Replace None if using spectrograms\n",
    "            alpha=0.25, beta=0.1, p=1, target_metric=4.5\n",
    "        )\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print(f\"Total loss for file {idx + 1}: {total_loss.item()}\")\n",
    "\n",
    "# Print average loss across all files\n",
    "average_loss = sum(losses) / len(losses)\n",
    "print(f\"\\nAverage Loss across all files: {average_loss:.6f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
