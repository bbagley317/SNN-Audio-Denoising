{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import snntorch as snn\n",
    "from snntorch import spikeplot as splt\n",
    "from snntorch import spikegen\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "\n",
    "# self.gated_spiking = nn.Sequential(\n",
    "        #     nn.Linear(input_dim, hidden_dim),\n",
    "        #     nn.Sigmoid()  # Simulates gating\n",
    "        # )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullbandModel(nn.Module):\n",
    "    def __init__(self, freq_bins, time_bins, hidden_dim, beta=0.9):\n",
    "        \"\"\"\n",
    "        Fullband Model with normalization, spiking neuron layer, and a linear layer.\n",
    "        Args:\n",
    "        - freq_bins: Number of frequency bins in the spectrogram.\n",
    "        - time_bins: Number of time bins in the spectrogram.\n",
    "        - hidden_dim: Number of hidden units for the spiking neuron layer.\n",
    "        - beta: Decay parameter for the LIF neuron.\n",
    "        \"\"\"\n",
    "        super(FullbandModel, self).__init__()\n",
    "        \n",
    "        self.freq_bins = freq_bins\n",
    "        self.time_bins = time_bins\n",
    "        self.input_dim = freq_bins * time_bins  # Flattened input feature size\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        # Layers\n",
    "        self.normalization = nn.LayerNorm(self.input_dim)  # Normalize input features\n",
    "        self.spikingneuron = snn.Leaky(beta=beta)          # Leaky Integrate-and-Fire neuron\n",
    "        self.linear = nn.Linear(self.input_dim, self.hidden_dim)  # Linear transformation\n",
    "\n",
    "    def forward(self, x, num_steps=10):\n",
    "        \"\"\"\n",
    "        Forward pass for the FullbandModel with time-stepped spiking neuron dynamics.\n",
    "        Args:\n",
    "        - x: Input tensor of shape (batch_size, frequency_bins, time_bins).\n",
    "        - num_steps: Number of time steps for spiking neuron simulation.\n",
    "        Returns:\n",
    "        - spk_rec: Spiking activity across timesteps (num_steps, batch_size, hidden_dim).\n",
    "        - mem_rec: Membrane potential across timesteps (num_steps, batch_size, hidden_dim).\n",
    "        \"\"\"\n",
    "        batch_size, freq_bins, time_bins = x.shape\n",
    "        assert freq_bins == self.freq_bins and time_bins == self.time_bins, \\\n",
    "            \"Input dimensions must match model initialization dimensions.\"\n",
    "\n",
    "        # Flatten the spectrogram into 1D vectors\n",
    "        x = x.view(batch_size, -1)  # Shape: (batch_size, input_dim)\n",
    "\n",
    "        # Normalize the input\n",
    "        x = self.normalization(x)\n",
    "\n",
    "        # Initialize membrane potentials for the spiking neuron\n",
    "        mem = torch.zeros((batch_size, self.hidden_dim), dtype=torch.float32, device=x.device)\n",
    "\n",
    "        # Record spiking activity and membrane potentials\n",
    "        spk_rec = []\n",
    "        mem_rec = []\n",
    "\n",
    "        for step in range(num_steps):\n",
    "            # Linear transformation\n",
    "            cur = self.linear(x)\n",
    "\n",
    "            # Spiking neuron dynamics\n",
    "            spk, mem = self.spikingneuron(cur, mem)\n",
    "\n",
    "            # Record outputs\n",
    "            spk_rec.append(spk)\n",
    "            mem_rec.append(mem)\n",
    "\n",
    "        # Stack outputs across timesteps\n",
    "        spk_rec = torch.stack(spk_rec, dim=0)  # Shape: (num_steps, batch_size, hidden_dim)\n",
    "        mem_rec = torch.stack(mem_rec, dim=0)  # Shape: (num_steps, batch_size, hidden_dim)\n",
    "\n",
    "        return spk_rec, mem_rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubbandModel(nn.Module):\n",
    "    def __init__(self, hidden_dim, num_steps, beta=0.9):\n",
    "        \"\"\"\n",
    "        Subband Model with normalization, spiking neuron layer, and a linear layer.\n",
    "        Args:\n",
    "        - hidden_dim: Number of hidden units for the spiking neuron layer.\n",
    "        - num_steps: Number of timesteps for spiking neuron simulation.\n",
    "        - beta: Decay parameter for the LIF neuron.\n",
    "        \"\"\"\n",
    "        super(SubbandModel, self).__init__()\n",
    "\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_steps = num_steps\n",
    "        self.spikingneuron = snn.Leaky(beta=beta)  # Leaky Integrate-and-Fire neuron\n",
    "        self.linear = None  # Linear layer to be initialized dynamically\n",
    "\n",
    "    def forward(self, x, num_steps=None):\n",
    "        \"\"\"\n",
    "        Forward pass for the SubbandModel with time-stepped spiking neuron dynamics.\n",
    "        Args:\n",
    "        - x: Input tensor of shape (batch_size, subband_dim).\n",
    "        - num_steps: Number of time steps for spiking neuron simulation.\n",
    "        Returns:\n",
    "        - spk_rec: Spiking activity across timesteps (num_steps, batch_size, hidden_dim).\n",
    "        - mem_rec: Membrane potential across timesteps (num_steps, batch_size, hidden_dim).\n",
    "        \"\"\"\n",
    "        if num_steps is None:\n",
    "            num_steps = self.num_steps\n",
    "\n",
    "        batch_size, subband_dim = x.shape\n",
    "\n",
    "        # Initialize normalization and linear layers dynamically\n",
    "        if not hasattr(self, 'normalization') or self.normalization is None:\n",
    "            self.normalization = nn.LayerNorm(subband_dim).to(x.device)\n",
    "        if self.linear is None:\n",
    "            self.linear = nn.Linear(subband_dim, self.hidden_dim).to(x.device)\n",
    "\n",
    "        # Normalize input\n",
    "        x = self.normalization(x)\n",
    "\n",
    "        # Initialize membrane potentials for the spiking neuron\n",
    "        mem = torch.zeros((batch_size, self.hidden_dim), dtype=torch.float32, device=x.device)\n",
    "\n",
    "        # Record the outputs\n",
    "        spk_rec = []\n",
    "        mem_rec = []\n",
    "\n",
    "        for step in range(num_steps):\n",
    "            cur = self.linear(x)  # Linear transformation\n",
    "            spk, mem = self.spikingneuron(cur, mem)  # Spiking neuron dynamics\n",
    "            spk_rec.append(spk)\n",
    "            mem_rec.append(mem)\n",
    "\n",
    "        # Stack the recorded values across timesteps\n",
    "        spk_rec = torch.stack(spk_rec, dim=0)  # Shape: (num_steps, batch_size, hidden_dim)\n",
    "        mem_rec = torch.stack(mem_rec, dim=0)  # Shape: (num_steps, batch_size, hidden_dim)\n",
    "\n",
    "        return spk_rec, mem_rec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency_partition(spectrogram, num_subbands):\n",
    "    \"\"\"\n",
    "    Splits the input tensor into subbands along the second dimension.\n",
    "    Args:\n",
    "    - spectrogram: Input tensor of shape (batch_size, hidden_dim).\n",
    "    - num_subbands: Number of subbands to split the hidden_dim into.\n",
    "    Returns:\n",
    "    - subbands: List of tensors, each of shape (batch_size, subband_size).\n",
    "    \"\"\"\n",
    "    batch_size, hidden_dim = spectrogram.shape\n",
    "    subband_size = hidden_dim // num_subbands\n",
    "\n",
    "    # Split along the hidden_dim axis\n",
    "    subbands = torch.split(spectrogram, subband_size, dim=1)\n",
    "    print(f\"Number of Subbands (fp func): {len(subbands)}\")\n",
    "    return subbands\n",
    "\n",
    "\n",
    "def frequency_reconstruct(subbands):\n",
    "    \"\"\"\n",
    "    Reconstructs the full spectrogram from processed subbands.\n",
    "    Args:\n",
    "    - subbands: List of tensors, each of shape (batch_size, subband_size, time_bins).\n",
    "    Returns:\n",
    "    - reconstructed: Tensor of shape (batch_size, frequency_bins, time_bins).\n",
    "    \"\"\"\n",
    "    # Concatenate the processed subbands along the frequency axis\n",
    "    reconstructed = torch.cat(subbands, dim=1)\n",
    "    return reconstructed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IntegratedModel(nn.Module):\n",
    "    def __init__(self, freq_bins, time_bins, hidden_dim, num_steps, num_subbands, beta=0.9):\n",
    "        \"\"\"\n",
    "        Integrated model combining FullbandModel, frequency partitioning, and SubbandModels.\n",
    "        Args:\n",
    "        - freq_bins: Number of frequency bins in the spectrogram.\n",
    "        - time_bins: Number of time bins in the spectrogram.\n",
    "        - hidden_dim: Number of hidden units for the spiking neuron layer.\n",
    "        - num_steps: Number of timesteps for spiking neuron simulation.\n",
    "        - num_subbands: Number of frequency subbands.\n",
    "        - beta: Decay parameter for the LIF neuron.\n",
    "        \"\"\"\n",
    "        super(IntegratedModel, self).__init__()\n",
    "\n",
    "        self.freq_bins = freq_bins\n",
    "        self.time_bins = time_bins\n",
    "        self.num_subbands = num_subbands\n",
    "\n",
    "        subband_size = freq_bins // num_subbands\n",
    "\n",
    "        # Fullband model\n",
    "        self.fullband_model = FullbandModel(freq_bins, time_bins, hidden_dim, beta)\n",
    "\n",
    "        # Subband models\n",
    "        self.subband_models = nn.ModuleList([\n",
    "            SubbandModel(hidden_dim, num_steps, beta)\n",
    "            for _ in range(num_subbands)\n",
    "        ])\n",
    "        \n",
    "        print(f\"Number of Subband Models: {len(self.subband_models)}\")\n",
    "\n",
    "    def forward(self, x, num_steps=10):\n",
    "        \"\"\"\n",
    "        Forward pass through FullbandModel, frequency partitioning, and SubbandModels.\n",
    "        Args:\n",
    "        - x: Input tensor of shape (batch_size, frequency_bins, time_bins).\n",
    "        - num_steps: Number of time steps for spiking neuron simulation.\n",
    "        Returns:\n",
    "        - subband_outputs: List of tensors, each corresponding to the output of a SubbandModel.\n",
    "        \"\"\"\n",
    "        # Fullband processing\n",
    "        fullband_output, _ = self.fullband_model(x, num_steps)\n",
    "\n",
    "        # Use the last timestep output for partitioning\n",
    "        subbands = frequency_partition(fullband_output[-1], self.num_subbands)\n",
    "        print(f\"Number of Subbands: {len(subbands)}\")\n",
    "\n",
    "        # Subband processing\n",
    "        subband_outputs = [\n",
    "            self.subband_models[i](subband, num_steps=num_steps)[0][-1]\n",
    "            for i, subband in enumerate(subbands)\n",
    "        ]\n",
    "\n",
    "        return subband_outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded tensor shape: torch.Size([1, 128, 860])\n",
      "Number of Subband Models: 4\n",
      "Input tensor shape: torch.Size([1, 128, 860])\n",
      "Model freq_bins: 128\n",
      "Model time_bins: 860\n",
      "Number of Subbands (fp func): 4\n",
      "Number of Subbands: 4\n",
      "Subband 1 output shape: torch.Size([1, 64])\n",
      "Subband 2 output shape: torch.Size([1, 64])\n",
      "Subband 3 output shape: torch.Size([1, 64])\n",
      "Subband 4 output shape: torch.Size([1, 64])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Define paths\n",
    "feature_dir = \"E:/CS541 - Deep Learning/noisy_audio_np\"\n",
    "label_dir = \"E:/CS541 - Deep Learning/clean_audio_np\"\n",
    "\n",
    "# Load a sample feature and label\n",
    "test_feature_file = os.path.join(feature_dir, \"noisy_spectrogram1.npy\")\n",
    "test_label_file = os.path.join(label_dir, \"clean_spectrogram1.npy\")\n",
    "\n",
    "# Load the .npy files\n",
    "noisy_spectrogram = np.load(test_feature_file)  # Shape: (frequency_bins, time_bins)\n",
    "clean_spectrogram = np.load(test_label_file)    # Shape: (frequency_bins, time_bins)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "noisy_tensor = torch.tensor(noisy_spectrogram, dtype=torch.float32).unsqueeze(0)  # Add batch dimension\n",
    "clean_tensor = torch.tensor(clean_spectrogram, dtype=torch.float32).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "noisy_spectrogram = np.load(\"E:/CS541 - Deep Learning/noisy_audio_np/noisy_spectrogram1.npy\")  # Shape: (freq_bins, time_bins)\n",
    "noisy_tensor = torch.tensor(noisy_spectrogram, dtype=torch.float32).unsqueeze(0)  # Add batch dimension\n",
    "print(\"Loaded tensor shape:\", noisy_tensor.shape)\n",
    "\n",
    "\n",
    "# Parameters for the model\n",
    "freq_bins = noisy_tensor.shape[1]  # Frequency bins\n",
    "time_bins = noisy_tensor.shape[2]  # Time bins\n",
    "hidden_dim = 64  # Hidden layer size for spiking neurons\n",
    "num_steps = 10   # Number of timesteps for spiking neuron simulation\n",
    "num_subbands = 4  # Number of frequency partitions\n",
    "beta = 0.9       # Decay parameter for LIF neurons\n",
    "\n",
    "# Initialize the IntegratedModel\n",
    "model = IntegratedModel(freq_bins, time_bins, hidden_dim, num_steps, num_subbands, beta).to(\"cuda\")\n",
    "\n",
    "# Move tensors to GPU if available\n",
    "noisy_tensor = noisy_tensor.to(\"cuda\")\n",
    "print(\"Input tensor shape:\", noisy_tensor.shape)  # Should match (batch_size, freq_bins, time_bins)\n",
    "clean_tensor = clean_tensor.to(\"cuda\")\n",
    "print(\"Model freq_bins:\", model.freq_bins)\n",
    "print(\"Model time_bins:\", model.time_bins)\n",
    "\n",
    "# Forward pass\n",
    "subband_outputs = model(noisy_tensor, num_steps=num_steps)\n",
    "\n",
    "# Print the shape of subband outputs for validation\n",
    "for i, subband_output in enumerate(subband_outputs):\n",
    "    print(f\"Subband {i+1} output shape: {subband_output.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Model initialization\n",
    "# freq_bins = 128   # Number of Mel frequency bins\n",
    "# time_bins = 431   # Number of time bins in each spectrogram\n",
    "# input_dim = freq_bins * time_bins  # Flattened input dimension\n",
    "# hidden_dim = 512  # Hidden layer size\n",
    "# num_steps = 25    # Number of timesteps for spiking dynamics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
