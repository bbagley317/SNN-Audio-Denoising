{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import snntorch as snn\n",
    "from snntorch import spikeplot as splt\n",
    "from snntorch import spikegen\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "\n",
    "# self.gated_spiking = nn.Sequential(\n",
    "        #     nn.Linear(input_dim, hidden_dim),\n",
    "        #     nn.Sigmoid()  # Simulates gating\n",
    "        # )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullbandModel(nn.Module):\n",
    "    def __init__(self, freq_bins, time_bins, hidden_dim, beta=0.9):\n",
    "        \"\"\"\n",
    "        Fullband Model with normalization, spiking neuron layer, and a linear layer.\n",
    "        Args:\n",
    "        - freq_bins: Number of frequency bins in the spectrogram.\n",
    "        - time_bins: Number of time bins in the spectrogram.\n",
    "        - hidden_dim: Number of hidden units for the spiking neuron layer.\n",
    "        - beta: Decay parameter for the LIF neuron.\n",
    "        \"\"\"\n",
    "        super(FullbandModel, self).__init__()\n",
    "        \n",
    "        self.freq_bins = freq_bins\n",
    "        self.time_bins = time_bins\n",
    "        self.input_dim = freq_bins * time_bins  # Flattened input feature size\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        # Layers\n",
    "        self.normalization = nn.LayerNorm(self.input_dim)  # Normalize input features\n",
    "        self.spikingneuron = snn.Leaky(beta=beta)          # Leaky Integrate-and-Fire neuron\n",
    "        self.linear = nn.Linear(self.input_dim, self.hidden_dim)  # Linear transformation\n",
    "\n",
    "    def forward(self, x, num_steps=10):\n",
    "        \"\"\"\n",
    "        Forward pass for the FullbandModel with time-stepped spiking neuron dynamics.\n",
    "        Args:\n",
    "        - x: Input tensor of shape (batch_size, frequency_bins, time_bins).\n",
    "        - num_steps: Number of time steps for spiking neuron simulation.\n",
    "        Returns:\n",
    "        - spk_rec: Spiking activity across timesteps (num_steps, batch_size, hidden_dim).\n",
    "        - mem_rec: Membrane potential across timesteps (num_steps, batch_size, hidden_dim).\n",
    "        \"\"\"\n",
    "        batch_size, freq_bins, time_bins = x.shape\n",
    "        assert freq_bins == self.freq_bins and time_bins == self.time_bins, \\\n",
    "            \"Input dimensions must match model initialization dimensions.\"\n",
    "\n",
    "        # Flatten the spectrogram into 1D vectors\n",
    "        x = x.view(batch_size, -1)  # Shape: (batch_size, input_dim)\n",
    "\n",
    "        # Normalize the input\n",
    "        x = self.normalization(x)\n",
    "\n",
    "        # Initialize membrane potentials for the spiking neuron\n",
    "        mem = torch.zeros((batch_size, self.hidden_dim), dtype=torch.float32, device=x.device)\n",
    "\n",
    "        # Record spiking activity and membrane potentials\n",
    "        spk_rec = []\n",
    "        mem_rec = []\n",
    "\n",
    "        for step in range(num_steps):\n",
    "            # Linear transformation\n",
    "            cur = self.linear(x)\n",
    "\n",
    "            # Spiking neuron dynamics\n",
    "            spk, mem = self.spikingneuron(cur, mem)\n",
    "\n",
    "            # Record outputs\n",
    "            spk_rec.append(spk)\n",
    "            mem_rec.append(mem)\n",
    "\n",
    "        # Stack outputs across timesteps\n",
    "        spk_rec = torch.stack(spk_rec, dim=0)  # Shape: (num_steps, batch_size, hidden_dim)\n",
    "        mem_rec = torch.stack(mem_rec, dim=0)  # Shape: (num_steps, batch_size, hidden_dim)\n",
    "\n",
    "        return spk_rec, mem_rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubbandModel(nn.Module):\n",
    "    def __init__(self, hidden_dim, num_steps, beta=0.7):\n",
    "        \"\"\"\n",
    "        Subband Model with normalization, spiking neuron layer, and a linear layer.\n",
    "        Args:\n",
    "        - hidden_dim: Number of hidden units for the spiking neuron layer.\n",
    "        - num_steps: Number of timesteps for spiking neuron simulation.\n",
    "        - beta: Decay parameter for the LIF neuron.\n",
    "        \"\"\"\n",
    "        super(SubbandModel, self).__init__()\n",
    "\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_steps = num_steps\n",
    "        self.spikingneuron = snn.Leaky(beta=beta)  # Leaky Integrate-and-Fire neuron\n",
    "        self.linear = None  # Linear layer to be initialized dynamically\n",
    "\n",
    "    def forward(self, x, num_steps=None):\n",
    "        \"\"\"\n",
    "        Forward pass for the SubbandModel with time-stepped spiking neuron dynamics.\n",
    "        Args:\n",
    "        - x: Input tensor of shape (batch_size, subband_dim).\n",
    "        - num_steps: Number of time steps for spiking neuron simulation.\n",
    "        Returns:\n",
    "        - spk_rec: Spiking activity across timesteps (num_steps, batch_size, hidden_dim).\n",
    "        - mem_rec: Membrane potential across timesteps (num_steps, batch_size, hidden_dim).\n",
    "        \"\"\"\n",
    "        if num_steps is None:\n",
    "            num_steps = self.num_steps\n",
    "\n",
    "        batch_size, subband_dim = x.shape\n",
    "\n",
    "        # Initialize normalization and linear layers dynamically\n",
    "        if not hasattr(self, 'normalization') or self.normalization is None:\n",
    "            self.normalization = nn.LayerNorm(subband_dim).to(x.device)\n",
    "        if self.linear is None:\n",
    "            self.linear = nn.Linear(subband_dim, self.hidden_dim).to(x.device)\n",
    "\n",
    "        # Normalize input\n",
    "        x = self.normalization(x)\n",
    "\n",
    "        # Initialize membrane potentials for the spiking neuron\n",
    "        mem = torch.zeros((batch_size, self.hidden_dim), dtype=torch.float32, device=x.device)\n",
    "\n",
    "        # Record the outputs\n",
    "        spk_rec = []\n",
    "        mem_rec = []\n",
    "\n",
    "        for step in range(num_steps):\n",
    "            cur = self.linear(x)  # Linear transformation\n",
    "            spk, mem = self.spikingneuron(cur, mem)  # Spiking neuron dynamics\n",
    "            spk_rec.append(spk)\n",
    "            mem_rec.append(mem)\n",
    "\n",
    "        # Stack the recorded values across timesteps\n",
    "        spk_rec = torch.stack(spk_rec, dim=0)  # Shape: (num_steps, batch_size, hidden_dim)\n",
    "        mem_rec = torch.stack(mem_rec, dim=0)  # Shape: (num_steps, batch_size, hidden_dim)\n",
    "\n",
    "        return spk_rec, mem_rec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency_partition(spectrogram, num_subbands):\n",
    "    \"\"\"\n",
    "    Splits the input tensor into subbands along the second dimension.\n",
    "    Args:\n",
    "    - spectrogram: Input tensor of shape (batch_size, hidden_dim).\n",
    "    - num_subbands: Number of subbands to split the hidden_dim into.\n",
    "    Returns:\n",
    "    - subbands: List of tensors, each of shape (batch_size, subband_size).\n",
    "    \"\"\"\n",
    "    batch_size, hidden_dim = spectrogram.shape\n",
    "    subband_size = hidden_dim // num_subbands\n",
    "\n",
    "    # Split along the hidden_dim axis\n",
    "    subbands = torch.split(spectrogram, subband_size, dim=1)\n",
    "    # print(f\"Number of Subbands (fp func): {len(subbands)}\")\n",
    "    return subbands\n",
    "\n",
    "\n",
    "def frequency_reconstruct(subbands):\n",
    "    \"\"\"\n",
    "    Reconstructs the full spectrogram from processed subbands.\n",
    "    Args:\n",
    "    - subbands: List of tensors, each of shape (batch_size, subband_size, time_bins).\n",
    "    Returns:\n",
    "    - reconstructed: Tensor of shape (batch_size, frequency_bins, time_bins).\n",
    "    \"\"\"\n",
    "    # Concatenate the processed subbands along the frequency axis\n",
    "    reconstructed = torch.cat(subbands, dim=1)\n",
    "    return reconstructed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepFilteringLayer(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, num_filters=64):\n",
    "        super(DeepFilteringLayer, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(input_dim, num_filters, kernel_size=3, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv1d(num_filters, num_filters, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv1d(num_filters, output_dim, kernel_size=1)\n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode='linear', align_corners=True)  # Add this layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.upsample(x)  # Upsample to match original dimensions\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IntegratedModel(nn.Module):\n",
    "    def __init__(self, freq_bins, time_bins, hidden_dim_full, hidden_dim_sub, num_steps, num_subbands, beta_full=0.9, beta_sub =0.7):\n",
    "        \"\"\"\n",
    "        Integrated model with FullbandModel, SubbandModels, and per-subband DeepFilteringLayers.\n",
    "        Args:\n",
    "        - freq_bins: Number of frequency bins in the spectrogram.\n",
    "        - time_bins: Number of time bins in the spectrogram.\n",
    "        - hidden_dim: Number of hidden units for the spiking neuron layer.\n",
    "        - num_steps: Number of timesteps for spiking neuron simulation.\n",
    "        - num_subbands: Number of frequency subbands.\n",
    "        - beta: Decay parameter for the LIF neuron.\n",
    "        \"\"\"\n",
    "        super(IntegratedModel, self).__init__()\n",
    "\n",
    "        self.freq_bins = freq_bins\n",
    "        self.time_bins = time_bins\n",
    "        self.num_subbands = num_subbands\n",
    "        self.hidden_dim_full = hidden_dim_full\n",
    "        self.hidden_dim_sub = hidden_dim_sub\n",
    "\n",
    "\n",
    "        subband_size = freq_bins // num_subbands\n",
    "\n",
    "        # Fullband model\n",
    "        self.fullband_model = FullbandModel(freq_bins, time_bins, hidden_dim_full, beta_full)\n",
    "\n",
    "        # Subband models\n",
    "        self.subband_models = nn.ModuleList([\n",
    "            SubbandModel(hidden_dim_sub, num_steps, beta_sub)\n",
    "            for _ in range(num_subbands)\n",
    "        ])\n",
    "\n",
    "        # Per-subband Deep Filtering Layers\n",
    "        self.deep_filtering_layers = nn.ModuleList([\n",
    "            DeepFilteringLayer(input_dim=hidden_dim_sub, output_dim=subband_size)\n",
    "            for _ in range(num_subbands)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x, num_steps=10, clean_time_bins=None):\n",
    "        \"\"\"\n",
    "        Forward pass through the IntegratedModel.\n",
    "        Args:\n",
    "        - x: Input tensor of shape (batch_size, frequency_bins, time_bins).\n",
    "        - num_steps: Number of time steps for spiking neuron simulation.\n",
    "        - clean_time_bins: Time bins of the clean tensor for interpolation (optional).\n",
    "        Returns:\n",
    "        - filtered_output: Tensor after deep filtering and interpolation.\n",
    "        \"\"\"\n",
    "        # Fullband processing\n",
    "        fullband_output, _ = self.fullband_model(x, num_steps)\n",
    "\n",
    "        # Subband processing\n",
    "        subbands = frequency_partition(fullband_output[-1], self.num_subbands)\n",
    "        subband_outputs = [\n",
    "            self.subband_models[i](subband, num_steps=num_steps)[0][-1]\n",
    "            for i, subband in enumerate(subbands)\n",
    "        ]\n",
    "\n",
    "        # Per-subband deep filtering\n",
    "        filtered_subbands = [\n",
    "            self.deep_filtering_layers[i](subband_output.unsqueeze(-1)).squeeze(-1)\n",
    "            for i, subband_output in enumerate(subband_outputs)\n",
    "        ]\n",
    "\n",
    "        # Concatenate filtered subbands along the feature dimension\n",
    "        concatenated_output = torch.cat(filtered_subbands, dim=1)  # Shape: (batch_size, freq_bins)\n",
    "\n",
    "        # Add a singleton spatial dimension for interpolation\n",
    "        concatenated_output = concatenated_output.unsqueeze(-1)  # Shape: (batch_size, freq_bins, 1)\n",
    "\n",
    "        # Use clean_time_bins for interpolation if provided\n",
    "        target_time_bins = clean_time_bins if clean_time_bins is not None else self.time_bins\n",
    "\n",
    "        # Interpolate to match the original spectrogram dimensions\n",
    "        interpolated_output = torch.nn.functional.interpolate(\n",
    "            concatenated_output, size=(self.freq_bins, target_time_bins), mode='bilinear', align_corners=True\n",
    "        )\n",
    "\n",
    "        # Remove the singleton spatial dimension\n",
    "        filtered_output = interpolated_output.squeeze(-1)  # Shape: (batch_size, freq_bins, target_time_bins)\n",
    "\n",
    "        return filtered_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def si_snr_loss(prediction, target, eps=1e-8):\n",
    "    \"\"\"\n",
    "    Compute the Scale-invariant Signal-to-Noise Ratio (SI-SNR) loss.\n",
    "    \n",
    "    Args:\n",
    "        prediction (torch.Tensor): The predicted tensor (batch_size, freq_bins, time_bins).\n",
    "        target (torch.Tensor): The ground truth clean tensor (batch_size, freq_bins, time_bins).\n",
    "        eps (float): A small value to prevent division by zero.\n",
    "    \n",
    "    Returns:\n",
    "        torch.Tensor: The SI-SNR loss.\n",
    "    \"\"\"\n",
    "    # Normalize the target\n",
    "    target_norm = target - target.mean(dim=-1, keepdim=True)  # Mean-centered target\n",
    "    prediction_norm = prediction - prediction.mean(dim=-1, keepdim=True)  # Mean-centered prediction\n",
    "\n",
    "    # Compute dot product between target and prediction\n",
    "    target_dot = torch.sum(target_norm * prediction_norm, dim=-1, keepdim=True)\n",
    "    \n",
    "    # Compute the magnitude of target and prediction\n",
    "    target_mag = torch.sum(target_norm ** 2, dim=-1, keepdim=True)\n",
    "    prediction_mag = torch.sum(prediction_norm ** 2, dim=-1, keepdim=True)\n",
    "    \n",
    "    # Compute the scale-invariant SNR (SI-SNR)\n",
    "    si_snr = 20 * torch.log10((target_dot + eps) / (target_mag - target_dot + eps))\n",
    "    \n",
    "    # Return the negative SI-SNR to use as a loss (we want to maximize SI-SNR, hence minimizing negative SI-SNR)\n",
    "    return -torch.mean(si_snr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/3:   0%|          | 0/16 [00:00<?, ?it/s]C:\\Users\\B\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\loss.py:608: UserWarning: Using a target size (torch.Size([1, 128, 1938])) that is different to the input size (torch.Size([1, 126, 128, 1938])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "Training Epoch 1/3: 100%|██████████| 16/16 [00:20<00:00,  1.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 - Loss: 4142.729324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2/3: 100%|██████████| 16/16 [00:20<00:00,  1.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 - Loss: 4059.420914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3/3: 100%|██████████| 16/16 [00:20<00:00,  1.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 - Loss: 3750.012527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating on Test Set: 100%|██████████| 4/4 [00:01<00:00,  3.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Loss (SI-SNR) on Test Set: 3420.245972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3420.2459716796875"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm  # For tracking progress\n",
    "\n",
    "# Paths to the feature and label directories\n",
    "feature_dir = \"../npy_audio/numpy_spectrograms/noisy_audio_np\"\n",
    "label_dir = \"../npy_audio/numpy_spectrograms/clean_audio_np\"\n",
    "\n",
    "# Load all feature and label file paths\n",
    "feature_files = sorted(os.listdir(feature_dir))[0:20]\n",
    "label_files = sorted(os.listdir(label_dir))[0:20]\n",
    "\n",
    "assert len(feature_files) == len(label_files), \"Mismatch between feature and label file counts!\"\n",
    "\n",
    "# Split into training and test sets\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(\n",
    "    feature_files, label_files, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Model parameters\n",
    "freq_bins, time_bins = 128, 860  # Based on the dimensions of your spectrograms\n",
    "hidden_dim_full = 240            # Hidden dimension for fullband spiking neurons\n",
    "hidden_dim_sub = 160             # Hidden dimension for sub band spiking neurons\n",
    "num_steps = 20                   # Number of timesteps for spiking neurons\n",
    "num_subbands = 3                 # Number of subbands (adjusted for even division)\n",
    "beta_full = 0.9                  # Decay parameter for Fullband LIF neurons\n",
    "beta_sub = 0.9                   # Decay parameter for Subband LIF neurons\n",
    "\n",
    "# Initialize the model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = IntegratedModel(freq_bins, time_bins, hidden_dim_full, hidden_dim_sub, num_steps, num_subbands, beta_full, beta_sub).to(device)\n",
    "\n",
    "# Loss function and optimizer\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
    "\n",
    "#print(\"Integrated model parameters\")\n",
    "#for name, param in model.named_parameters(): print(f\"Parameter Name: {name}, Shape: {param.shape}\")\n",
    "\n",
    "def train_model(model, features, labels, num_epochs=3):\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = 0.0\n",
    "        for idx in tqdm(range(len(features)), desc=f\"Training Epoch {epoch + 1}/{num_epochs}\"):\n",
    "            # Load feature and label\n",
    "            feature_path = os.path.join(feature_dir, features[idx])\n",
    "            label_path = os.path.join(label_dir, labels[idx])\n",
    "\n",
    "            noisy_tensor = torch.tensor(np.load(feature_path)).unsqueeze(0).to(device)\n",
    "            clean_tensor = torch.tensor(np.load(label_path)).unsqueeze(0).to(device)\n",
    "\n",
    "            clean_time_bins = clean_tensor.shape[2]\n",
    "\n",
    "            # Forward pass\n",
    "            optimizer.zero_grad()\n",
    "            filtered_output = model(noisy_tensor, num_steps=num_steps, clean_time_bins=clean_time_bins)\n",
    "\n",
    "            # Compute loss\n",
    "            loss = loss_fn(filtered_output, clean_tensor)\n",
    "            #loss = si_snr_loss(filtered_output, clean_tensor)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs} - Loss: {epoch_loss / len(features):.6f}\")\n",
    "\n",
    "def evaluate_model(model, features, labels):\n",
    "    losses = []\n",
    "    with torch.no_grad():\n",
    "        for idx in tqdm(range(len(features)), desc=\"Evaluating on Test Set\"):\n",
    "            # Load feature and label\n",
    "            feature_path = os.path.join(feature_dir, features[idx])\n",
    "            label_path = os.path.join(label_dir, labels[idx])\n",
    "\n",
    "            noisy_tensor = torch.tensor(np.load(feature_path)).unsqueeze(0).to(device)\n",
    "            clean_tensor = torch.tensor(np.load(label_path)).unsqueeze(0).to(device)\n",
    "\n",
    "            clean_time_bins = clean_tensor.shape[2]\n",
    "\n",
    "            # Forward pass\n",
    "            filtered_output = model(noisy_tensor, num_steps=num_steps, clean_time_bins=clean_time_bins)\n",
    "\n",
    "            # Compute loss\n",
    "            loss = loss_fn(filtered_output, clean_tensor)\n",
    "            #loss = si_snr_loss(filtered_output, clean_tensor)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "    average_loss = sum(losses) / len(losses)\n",
    "    print(f\"\\nAverage Loss (MSE) on Test Set: {average_loss:.6f}\")\n",
    "    return average_loss\n",
    "\n",
    "train_model(model, train_features, train_labels, num_epochs=3)\n",
    "evaluate_model(model, test_features, test_labels)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
