# -*- coding: utf-8 -*-
"""Models that didn't show any improvements.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17pUsSbkD1qXiwaJ3fnHRfqmBWKOsewIV
"""

!pip install librosa
!pip install pesq
!pip install pystoi

import os
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader, random_split
import librosa
import numpy as np
import matplotlib.pyplot as plt
import librosa.display
from pesq import pesq
from pystoi import stoi
import copy
from IPython.display import Audio
import torch.nn.functional as F

from google.colab import drive
drive.mount('/content/drive')

# Define constants
SAMPLE_RATE = 48000

BASE_DIR = "/content/drive/My Drive/Deep_Learning"
CLEAN_AUDIO_PATH = os.path.join(BASE_DIR, "Clean_audio")
NOISY_AUDIO_PATH = os.path.join(BASE_DIR, "Noisy_audio")

noisy_files = [f for f in os.listdir(NOISY_AUDIO_PATH) if f.endswith('.wav')]

standard_noisy_files = [f for f in noisy_files if f.startswith('noisy_audio')]
filtered_noisy_files = [f for f in noisy_files if f.startswith('filtered_noisy_audio')]

# Print counts
print(f"Total Noisy Audio Files: {len(noisy_files)}")
print(f"Standard Noisy Audio Files: {len(standard_noisy_files)}")
print(f"Filtered Noisy Audio Files: {len(filtered_noisy_files)}")

# Print first 10 files of each category
print("\nFirst 10 Standard Noisy Audio Files:")
print(standard_noisy_files[:10])

print("\nFirst 10 Filtered Noisy Audio Files:")
print(filtered_noisy_files[:10])

def extract_numeric_id(filename, prefix):
    """
    Extracts the numeric identifier from a filename.
    For example, 'clean_audio10.wav' with prefix 'clean_audio' returns 10.
    """
    try:
        return int(filename.replace(prefix, '').replace('.wav', ''))
    except ValueError:
        print(f"Error extracting numeric ID from filename: {filename}")
        return None

clean_ids = set()
for f in os.listdir(CLEAN_AUDIO_PATH):
    if f.endswith('.wav') and f.startswith('clean_audio'):
        id_ = extract_numeric_id(f, 'clean_audio')
        if id_ is not None:
            clean_ids.add(id_)

noisy_ids = set()
for f in standard_noisy_files:
    if f.endswith('.wav') and f.startswith('noisy_audio'):
        id_ = extract_numeric_id(f, 'noisy_audio')
        if id_ is not None:
            noisy_ids.add(id_)

# Find common IDs
common_ids = sorted(list(clean_ids.intersection(noisy_ids)))

print(f"Total Clean Audio Files: {len(clean_ids)}")
print(f"Total Standard Noisy Audio Files: {len(noisy_ids)}")
print(f"Total Common IDs: {len(common_ids)}")

selected_ids = common_ids[:50]
print(f"Selected IDs (first 50): {selected_ids}")

selected_clean_files = [f"clean_audio{idx}.wav" for idx in selected_ids]
selected_noisy_files = [f"noisy_audio{idx}.wav" for idx in selected_ids]

print(f"Selected {len(selected_clean_files)} Clean Audio Files:")
print(selected_clean_files)

print(f"\nSelected {len(selected_noisy_files)} Noisy Audio Files:")
print(selected_noisy_files)

missing_clean = [f for f in selected_clean_files if not os.path.exists(os.path.join(CLEAN_AUDIO_PATH, f))]
if missing_clean:
    print("Missing Clean Audio Files:")
    for f in missing_clean:
        print(f)
else:
    print("All selected clean audio files exist.")

missing_noisy = [f for f in selected_noisy_files if not os.path.exists(os.path.join(NOISY_AUDIO_PATH, f))]
if missing_noisy:
    print("Missing Noisy Audio Files:")
    for f in missing_noisy:
        print(f)
else:
    print("All selected noisy audio files exist.")

class PairedAudioDataset(Dataset):
    def __init__(self, clean_audio_dir, noisy_audio_dir, clean_files, noisy_files, transform=None, n_fft=2048, hop_length=512, max_freq=1025, max_time=936):
        """
        Args:
            clean_audio_dir (str): Directory with clean audio files.
            noisy_audio_dir (str): Directory with noisy audio files.
            clean_files (list): List of clean audio filenames.
            noisy_files (list): List of noisy audio filenames.
            transform (callable, optional): Optional transform to be applied on a sample.
            n_fft (int): Number of FFT components.
            hop_length (int): Number of samples between successive frames.
            max_freq (int): Maximum frequency bins for padding.
            max_time (int): Maximum time frames for padding.
        """
        self.clean_audio_dir = clean_audio_dir
        self.noisy_audio_dir = noisy_audio_dir
        self.transform = transform
        self.n_fft = n_fft
        self.hop_length = hop_length
        self.max_freq = max_freq
        self.max_time = max_time

        if len(clean_files) != len(noisy_files):
            raise ValueError("The number of clean and noisy audio files must be the same.")

        self.clean_files = clean_files
        self.noisy_files = noisy_files

        print(f"Total Paired Files: {len(self.clean_files)}")

    def __len__(self):
        return len(self.clean_files)

    def __getitem__(self, idx):
        clean_file = self.clean_files[idx]
        noisy_file = self.noisy_files[idx]

        clean_path = os.path.join(self.clean_audio_dir, clean_file)
        noisy_path = os.path.join(self.noisy_audio_dir, noisy_file)

        # Load audio
        clean_audio, sr = librosa.load(clean_path, sr=SAMPLE_RATE)
        noisy_audio, sr = librosa.load(noisy_path, sr=SAMPLE_RATE)

        min_length = min(len(clean_audio), len(noisy_audio))
        clean_audio = clean_audio[:min_length]
        noisy_audio = noisy_audio[:min_length]

        clean_spec = librosa.stft(clean_audio, n_fft=self.n_fft, hop_length=self.hop_length)
        noisy_spec = librosa.stft(noisy_audio, n_fft=self.n_fft, hop_length=self.hop_length)

        clean_mag = librosa.amplitude_to_db(np.abs(clean_spec))
        noisy_mag = librosa.amplitude_to_db(np.abs(noisy_spec))

        clean_mag = (clean_mag - clean_mag.min()) / (clean_mag.max() - clean_mag.min())
        noisy_mag = (noisy_mag - noisy_mag.min()) / (noisy_mag.max() - noisy_mag.min())

        clean_mag = clean_mag[np.newaxis, :, :]
        noisy_mag = noisy_mag[np.newaxis, :, :]

        clean_tensor = torch.tensor(clean_mag, dtype=torch.float32)
        noisy_tensor = torch.tensor(noisy_mag, dtype=torch.float32)

        pad_time = max(0, self.max_time - noisy_tensor.shape[-1])
        pad_freq = max(0, self.max_freq - noisy_tensor.shape[-2])

        clean_tensor = F.pad(clean_tensor, (0, pad_time, 0, pad_freq))
        noisy_tensor = F.pad(noisy_tensor, (0, pad_time, 0, pad_freq))

        clean_tensor = clean_tensor[:, :self.max_freq, :self.max_time]
        noisy_tensor = noisy_tensor[:, :self.max_freq, :self.max_time]

        if self.transform:
            clean_tensor = self.transform(clean_tensor)
            noisy_tensor = self.transform(noisy_tensor)

        return noisy_tensor, clean_tensor

# dataset with the first 50 samples
dataset = PairedAudioDataset(
    clean_audio_dir=CLEAN_AUDIO_PATH,
    noisy_audio_dir=NOISY_AUDIO_PATH,
    clean_files=selected_clean_files,
    noisy_files=selected_noisy_files,
    max_freq=1025,
    max_time=937
)

# Define split ratios
train_ratio = 0.7
val_ratio = 0.15
test_ratio = 0.15

# Calculate split lengths
total_size = len(dataset)
train_size = int(train_ratio * total_size)
val_size = int(val_ratio * total_size)
test_size = total_size - train_size - val_size

# Perform the split
train_dataset, val_dataset, test_dataset = random_split(
    dataset, [train_size, val_size, test_size],
    generator=torch.Generator().manual_seed(42)  # For reproducibility
)

print(f"Training Samples: {len(train_dataset)}")
print(f"Validation Samples: {len(val_dataset)}")
print(f"Testing Samples: {len(test_dataset)}")

batch_size = 8

# Create DataLoaders
train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)
test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)

print(f"Train Loader: {len(train_loader)} batches")
print(f"Validation Loader: {len(val_loader)} batches")
print(f"Test Loader: {len(test_loader)} batches")

class DenoisingAutoencoder(nn.Module):
    def __init__(self):
        super(DenoisingAutoencoder, self).__init__()
        # Encoder
        self.encoder = nn.Sequential(
            nn.Conv2d(1, 16, kernel_size=3, padding=1),
            nn.BatchNorm2d(16),
            nn.ReLU(),
            nn.MaxPool2d(2, 2),
            nn.Conv2d(16, 32, kernel_size=3, padding=1),
            nn.BatchNorm2d(32),
            nn.ReLU(),
            nn.MaxPool2d(2, 2)
        )
        # Decoder
        self.decoder = nn.Sequential(
            nn.ConvTranspose2d(32, 16, kernel_size=2, stride=2),
            nn.BatchNorm2d(16),
            nn.ReLU(),
            nn.ConvTranspose2d(16, 1, kernel_size=2, stride=2, output_padding=1),
            nn.ReLU()
        )

    def forward(self, x):
        encoded = self.encoder(x)
        decoded = self.decoder(encoded)
        return decoded

class UNet(nn.Module):
    def __init__(self):
        super(UNet, self).__init__()

        self.enc1 = nn.Sequential(
            nn.Conv2d(1, 64, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.Conv2d(64, 64, kernel_size=3, padding=1),
            nn.ReLU()
        )
        self.pool1 = nn.MaxPool2d(2, 2)

        self.enc2 = nn.Sequential(
            nn.Conv2d(64, 128, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.Conv2d(128, 128, kernel_size=3, padding=1),
            nn.ReLU()
        )
        self.pool2 = nn.MaxPool2d(2, 2)


        self.bottleneck = nn.Sequential(
            nn.Conv2d(128, 256, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.Conv2d(256, 256, kernel_size=3, padding=1),
            nn.ReLU()
        )

        self.upconv2 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)
        self.dec2 = nn.Sequential(
            nn.Conv2d(256, 128, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.Conv2d(128, 128, kernel_size=3, padding=1),
            nn.ReLU()
        )

        # Modified upconv1 with output_padding=1
        self.upconv1 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2, output_padding=1)
        self.dec1 = nn.Sequential(
            nn.Conv2d(128, 64, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.Conv2d(64, 64, kernel_size=3, padding=1),
            nn.ReLU()
        )

        # Output layer
        self.conv_final = nn.Conv2d(64, 1, kernel_size=1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        # Encoder
        e1 = self.enc1(x)
        p1 = self.pool1(e1)

        e2 = self.enc2(p1)
        p2 = self.pool2(e2)

        # Bottleneck
        b = self.bottleneck(p2)
        # Decoder
        u2 = self.upconv2(b)
        u2 = torch.cat((u2, e2), dim=1)
        d2 = self.dec2(u2)

        u1 = self.upconv1(d2)
        u1 = torch.cat((u1, e1), dim=1)
        d1 = self.dec1(u1)

        # Output
        out = self.conv_final(d1)
        out = self.sigmoid(out)
        return out

# Device configuration
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"Using device: {device}")

# Initialize models
model_ae = DenoisingAutoencoder().to(device)
model_unet = UNet().to(device)

# Define individual loss functions
mse_loss = nn.MSELoss()
l1_loss = nn.L1Loss()

def combined_loss(output, target):
    return mse_loss(output, target) + l1_loss(output, target)

criterion = combined_loss

optimizer_ae = optim.Adam(model_ae.parameters(), lr=1e-3)
optimizer_unet = optim.Adam(model_unet.parameters(), lr=1e-3)

def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=50, patience=5):
    best_model_wts = copy.deepcopy(model.state_dict())
    best_val_loss = float('inf')
    trigger_times = 0

    for epoch in range(num_epochs):
        # Training Phase
        model.train()
        running_loss = 0.0
        for idx, (noisy, clean) in enumerate(train_loader):
            noisy = noisy.to(device)
            clean = clean.to(device)

            # Forward pass
            outputs = model(noisy)
            # Debugging: Print output and target shapes on first iteration
            if epoch == 0 and idx == 0:
                print(f"Output Shape: {outputs.shape}, Target Shape: {clean.shape}")

            # Check if output and target shapes match
            if outputs.shape != clean.shape:
                print(f"Shape mismatch! Output shape: {outputs.shape}, Target shape: {clean.shape}")
                # Crop the output and target to the minimum dimensions
                min_freq = min(outputs.shape[2], clean.shape[2])
                min_time = min(outputs.shape[3], clean.shape[3])
                outputs = outputs[:, :, :min_freq, :min_time]
                clean = clean[:, :, :min_freq, :min_time]
                print(f"Adjusted Output shape: {outputs.shape}, Adjusted Target shape: {clean.shape}")

            loss = criterion(outputs, clean)

            # Backward and optimize
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            running_loss += loss.item() * noisy.size(0)

        epoch_train_loss = running_loss / len(train_loader.dataset)

        # Validation Phase
        model.eval()
        running_val_loss = 0.0
        with torch.no_grad():
            for idx, (noisy, clean) in enumerate(val_loader):
                noisy = noisy.to(device)
                clean = clean.to(device)

                outputs = model(noisy)
                # Debugging: Print output and target shapes on first validation iteration
                if epoch == 0 and idx == 0:
                    print(f"Val Output Shape: {outputs.shape}, Val Target Shape: {clean.shape}")

                # Check if output and target shapes match
                if outputs.shape != clean.shape:
                    print(f"Validation Shape mismatch! Output shape: {outputs.shape}, Target shape: {clean.shape}")
                    # Crop the output and target to the minimum dimensions
                    min_freq = min(outputs.shape[2], clean.shape[2])
                    min_time = min(outputs.shape[3], clean.shape[3])
                    outputs = outputs[:, :, :min_freq, :min_time]
                    clean = clean[:, :, :min_freq, :min_time]
                    print(f"Adjusted Val Output shape: {outputs.shape}, Adjusted Val Target shape: {clean.shape}")

                loss = criterion(outputs, clean)

                running_val_loss += loss.item() * noisy.size(0)

        epoch_val_loss = running_val_loss / len(val_loader.dataset)

        print(f"Epoch [{epoch+1}/{num_epochs}] | Train Loss: {epoch_train_loss:.4f} | Val Loss: {epoch_val_loss:.4f}")

        # Early Stopping Check
        if epoch_val_loss < best_val_loss:
            best_val_loss = epoch_val_loss
            best_model_wts = copy.deepcopy(model.state_dict())
            trigger_times = 0
        else:
            trigger_times += 1
            if trigger_times >= patience:
                print("Early stopping triggered!")
                break

    # Load best model weights
    model.load_state_dict(best_model_wts)
    return model

print("Training Denoising Autoencoder...")

model_ae = train_model(
    model=model_ae,
    train_loader=train_loader,
    val_loader=val_loader,
    criterion=criterion,
    optimizer=optimizer_ae,
    num_epochs=50,
    patience=5
)

def calculate_snr(clean, denoised):
    """
    Calculates the Signal-to-Noise Ratio (SNR) in decibels.
    """
    clean_power = np.sum(clean ** 2)
    noise_power = np.sum((clean - denoised) ** 2)
    snr = 10 * np.log10(clean_power / (noise_power + 1e-8))
    return snr

def evaluate_model_performance(model, loader, device, sample_rate=16000):
    """
    Evaluates the model using SNR, PESQ, and STOI metrics.

    Args:
        model (nn.Module): The trained model.
        loader (DataLoader): DataLoader for the test set.
        device (torch.device): Device to perform computations on.
        sample_rate (int): Sampling rate for evaluation metrics.

    Returns:
        tuple: Average SNR, PESQ, and STOI scores.
    """
    model.eval()
    snrs = []
    pesqs = []
    stois = []

    with torch.no_grad():
        for idx, (noisy, clean) in enumerate(loader):
            noisy = noisy.to(device)
            clean = clean.to(device)

            # Forward pass
            output = model(noisy)

            output_np = output.cpu().numpy()[0, 0, :, :]
            clean_np = clean.cpu().numpy()[0, 0, :, :]

            # Invert spectrogram to amplitude
            denoised_amp = librosa.db_to_amplitude(output_np)
            clean_amp = librosa.db_to_amplitude(clean_np)

            # Invert STFT to time domain
            denoised_audio = librosa.istft(denoised_amp)
            clean_audio = librosa.istft(clean_amp)

            # Resample to 16kHz for PESQ and STOI
            denoised_resampled = librosa.resample(denoised_audio, orig_sr=SAMPLE_RATE, target_sr=sample_rate)
            clean_resampled = librosa.resample(clean_audio, orig_sr=SAMPLE_RATE, target_sr=sample_rate)

            # Ensure same length
            min_length = min(len(clean_resampled), len(denoised_resampled))
            clean_resampled = clean_resampled[:min_length]
            denoised_resampled = denoised_resampled[:min_length]

            # Calculate SNR
            snr = calculate_snr(clean_resampled, denoised_resampled)
            snrs.append(snr)

            # Calculate PESQ
            try:
                pesq_score = pesq(sample_rate, clean_resampled, denoised_resampled, 'wb')
            except:
                pesq_score = 0
            pesqs.append(pesq_score)

            # Calculate STOI
            stoi_score = stoi(clean_resampled, denoised_resampled, sample_rate, extended=False)
            stois.append(stoi_score)

    avg_snr = np.mean(snrs)
    avg_pesq = np.mean(pesqs)
    avg_stoi = np.mean(stois)

    print(f"Average SNR: {avg_snr:.2f} dB")
    print(f"Average PESQ: {avg_pesq:.2f}")
    print(f"Average STOI: {avg_stoi:.2f}")

    return avg_snr, avg_pesq, avg_stoi

print("Evaluating Denoising Autoencoder...")
snr_ae, pesq_ae, stoi_ae = evaluate_model_performance(model_ae, test_loader, device)

print("\nEvaluating U-Net...")
snr_unet, pesq_unet, stoi_unet = evaluate_model_performance(model_unet, test_loader, device)

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline

import matplotlib.pyplot as plt
import librosa.display

def plot_spectrogram(clean_audio, noisy_audio, denoised_audio, sr=SAMPLE_RATE, title_suffix=''):
    # Compute spectrograms
    clean_spec = librosa.stft(clean_audio)
    noisy_spec = librosa.stft(noisy_audio)
    denoised_spec = librosa.stft(denoised_audio)

    # Convert to dB
    clean_db = librosa.amplitude_to_db(np.abs(clean_spec))
    noisy_db = librosa.amplitude_to_db(np.abs(noisy_spec))
    denoised_db = librosa.amplitude_to_db(np.abs(denoised_spec))

    # Create subplots
    fig, axs = plt.subplots(3, 1, figsize=(15, 10))

    # Plot Clean Spectrogram
    img1 = librosa.display.specshow(clean_db, sr=sr, x_axis='time', y_axis='log', ax=axs[0])
    axs[0].set_title(f'Clean Spectrogram {title_suffix}')
    fig.colorbar(img1, ax=axs[0], format="%+2.0f dB")

    # Plot Noisy Spectrogram
    img2 = librosa.display.specshow(noisy_db, sr=sr, x_axis='time', y_axis='log', ax=axs[1])
    axs[1].set_title(f'Noisy Spectrogram {title_suffix}')
    fig.colorbar(img2, ax=axs[1], format="%+2.0f dB")

    # Plot Denoised Spectrogram
    img3 = librosa.display.specshow(denoised_db, sr=sr, x_axis='time', y_axis='log', ax=axs[2])
    axs[2].set_title(f'Denoised Spectrogram {title_suffix}')
    fig.colorbar(img3, ax=axs[2], format="%+2.0f dB")

    # Adjust layout
    plt.tight_layout()
    plt.show()

def plot_spectrogram_and_save(clean_audio, noisy_audio, denoised_audio, sr=SAMPLE_RATE, title_suffix='', save_path=None):
    # Compute spectrograms
    clean_spec = librosa.stft(clean_audio)
    noisy_spec = librosa.stft(noisy_audio)
    denoised_spec = librosa.stft(denoised_audio)

    # Convert to dB
    clean_db = librosa.amplitude_to_db(np.abs(clean_spec))
    noisy_db = librosa.amplitude_to_db(np.abs(noisy_spec))
    denoised_db = librosa.amplitude_to_db(np.abs(denoised_spec))

    # Create subplots
    fig, axs = plt.subplots(3, 1, figsize=(15, 10))

    # Plot Clean Spectrogram
    img1 = librosa.display.specshow(clean_db, sr=sr, x_axis='time', y_axis='log', ax=axs[0])
    axs[0].set_title(f'Clean Spectrogram {title_suffix}')
    fig.colorbar(img1, ax=axs[0], format="%+2.0f dB")

    # Plot Noisy Spectrogram
    img2 = librosa.display.specshow(noisy_db, sr=sr, x_axis='time', y_axis='log', ax=axs[1])
    axs[1].set_title(f'Noisy Spectrogram {title_suffix}')
    fig.colorbar(img2, ax=axs[1], format="%+2.0f dB")

    # Plot Denoised Spectrogram
    img3 = librosa.display.specshow(denoised_db, sr=sr, x_axis='time', y_axis='log', ax=axs[2])
    axs[2].set_title(f'Denoised Spectrogram {title_suffix}')
    fig.colorbar(img3, ax=axs[2], format="%+2.0f dB")

    # Adjust layout
    plt.tight_layout()

    if save_path:
        plt.savefig(save_path)
        print(f"Spectrogram saved at {save_path}")
    else:
        plt.show()

